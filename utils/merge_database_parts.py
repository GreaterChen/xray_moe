#!/usr/bin/env python3
"""
æ•°æ®åº“åˆ†æ‰¹æ–‡ä»¶åˆå¹¶å·¥å…·

è¿™ä¸ªè„šæœ¬ç”¨äºå°†BUILD_DATABASEé˜¶æ®µç”Ÿæˆçš„å¤šä¸ªåˆ†æ‰¹æ–‡ä»¶åˆå¹¶ä¸ºä¸€ä¸ªå®Œæ•´çš„æ•°æ®åº“æ–‡ä»¶ã€‚

ç”¨æ³•:
    python examples/merge_database_parts.py --input_dir /path/to/database/parts --output /path/to/merged_database.pkl
"""

import os
import argparse
import pickle
import numpy as np
from tqdm import tqdm


def merge_database_parts(input_dir, output_path, format_type="auto"):
    """
    åˆå¹¶å¤šä¸ªæ•°æ®åº“åˆ†æ‰¹æ–‡ä»¶
    
    Args:
        input_dir: åŒ…å«åˆ†æ‰¹æ–‡ä»¶çš„ç›®å½•
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        format_type: è¾“å‡ºæ ¼å¼ ("pkl", "npz", "auto")
    """
    print(f"å¼€å§‹åˆå¹¶æ•°æ®åº“åˆ†æ‰¹æ–‡ä»¶...")
    print(f"è¾“å…¥ç›®å½•: {input_dir}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_path}")
    
    # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
    if format_type == "auto":
        if output_path.endswith('.pkl'):
            format_type = "pkl"
        elif output_path.endswith('.npz'):
            format_type = "npz"
        else:
            raise ValueError("æ— æ³•ä»è¾“å‡ºæ–‡ä»¶åç¡®å®šæ ¼å¼ï¼Œè¯·æŒ‡å®š --format å‚æ•°")
    
    # æŸ¥æ‰¾åˆ†æ‰¹æ–‡ä»¶
    files_list_path = os.path.join(input_dir, "database_files.txt")
    
    if os.path.exists(files_list_path):
        # ä»æ–‡ä»¶åˆ—è¡¨è¯»å–
        with open(files_list_path, 'r') as f:
            filenames = [line.strip() for line in f.readlines()]
        file_paths = [os.path.join(input_dir, fname) for fname in filenames]
        print(f"ä» database_files.txt è¯»å–åˆ° {len(file_paths)} ä¸ªæ–‡ä»¶")
    else:
        # è‡ªåŠ¨æœç´¢
        npz_files = sorted([f for f in os.listdir(input_dir) 
                          if f.startswith('anatomical_database_part_') and f.endswith('.npz')])
        pkl_files = sorted([f for f in os.listdir(input_dir) 
                          if f.startswith('anatomical_database_part_') and f.endswith('.pkl')])
        
        if npz_files:
            file_paths = [os.path.join(input_dir, f) for f in npz_files]
            input_format = "npz"
        elif pkl_files:
            file_paths = [os.path.join(input_dir, f) for f in pkl_files]
            input_format = "pkl"
        else:
            raise ValueError("åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°æ•°æ®åº“åˆ†æ‰¹æ–‡ä»¶")
        
        print(f"è‡ªåŠ¨å‘ç° {len(file_paths)} ä¸ª {input_format.upper()} æ–‡ä»¶")
    
    # æ£€æµ‹è¾“å…¥æ ¼å¼
    if file_paths[0].endswith('.npz'):
        input_format = "npz"
    elif file_paths[0].endswith('.pkl'):
        input_format = "pkl"
    else:
        raise ValueError("æ— æ³•ç¡®å®šè¾“å…¥æ–‡ä»¶æ ¼å¼")
    
    # åˆå¹¶æ•°æ®
    merged_database = {}
    total_images = 0
    total_regions = 0
    
    print(f"\nå¼€å§‹åˆå¹¶ {len(file_paths)} ä¸ªæ–‡ä»¶...")
    
    for i, file_path in enumerate(tqdm(file_paths, desc="åˆå¹¶æ–‡ä»¶")):
        # åŠ è½½æ–‡ä»¶
        if input_format == "npz":
            npz_data = np.load(file_path, allow_pickle=True)
            part_data = npz_data['image_database'].item()
        elif input_format == "pkl":
            with open(file_path, 'rb') as f:
                part_data = pickle.load(f)
        
        # ç»Ÿè®¡ä¿¡æ¯
        part_images = len(part_data)
        part_regions = sum(img_data['detected_count'] for img_data in part_data.values())
        
        print(f"æ–‡ä»¶ {i+1}: {part_images} ä¸ªå›¾åƒ, {part_regions} ä¸ªæ£€æµ‹åŒºåŸŸ")
        
        # æ£€æŸ¥é‡å¤çš„image_id
        overlapping_keys = set(merged_database.keys()) & set(part_data.keys())
        if overlapping_keys:
            print(f"è­¦å‘Š: å‘ç°é‡å¤çš„å›¾åƒID: {len(overlapping_keys)} ä¸ª")
            print(f"å°†ä½¿ç”¨ååŠ è½½çš„æ•°æ®è¦†ç›–...")
        
        # åˆå¹¶æ•°æ®
        merged_database.update(part_data)
        total_images = len(merged_database)
        total_regions += part_regions
    
    print(f"\nåˆå¹¶å®Œæˆï¼")
    print(f"æ€»å›¾åƒæ•°: {total_images}")
    print(f"æ€»æ£€æµ‹åŒºåŸŸæ•°: {total_regions}")
    print(f"å¹³å‡æ¯å›¾åƒæ£€æµ‹åŒºåŸŸæ•°: {total_regions / total_images:.2f}")
    
    # ä¿å­˜åˆå¹¶åçš„æ•°æ®åº“
    print(f"\nä¿å­˜åˆå¹¶åçš„æ•°æ®åº“åˆ°: {output_path}")
    
    if format_type == "npz":
        np.savez_compressed(output_path, image_database=merged_database)
    elif format_type == "pkl":
        with open(output_path, 'wb') as f:
            pickle.dump(merged_database, f)
    
    print(f"åˆå¹¶å®Œæˆï¼æ•°æ®åº“å·²ä¿å­˜ä¸º {format_type.upper()} æ ¼å¼")
    
    return {
        "total_images": total_images,
        "total_regions": total_regions,
        "num_parts_merged": len(file_paths),
        "output_path": output_path
    }


def main():
    parser = argparse.ArgumentParser(description="åˆå¹¶æ•°æ®åº“åˆ†æ‰¹æ–‡ä»¶")
    parser.add_argument("--input_dir", help="åŒ…å«åˆ†æ‰¹æ–‡ä»¶çš„ç›®å½•", default="/mnt/chenlb/datasets/MIMIC/anatomical_database")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„", default="/mnt/chenlb/datasets/MIMIC/anatomical_database/anatomical_database.npz")
    parser.add_argument("--format", choices=["pkl", "npz", "auto"], default="npz", 
                       help="è¾“å‡ºæ ¼å¼ (é»˜è®¤æ ¹æ®æ–‡ä»¶æ‰©å±•åè‡ªåŠ¨æ£€æµ‹)")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.isdir(args.input_dir):
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    try:
        result = merge_database_parts(args.input_dir, args.output, args.format)
        print(f"\nâœ… åˆå¹¶æˆåŠŸ!")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {result['output_path']}")
        print(f"ğŸ“Š å›¾åƒæ•°é‡: {result['total_images']}")
        print(f"ğŸ¯ æ£€æµ‹åŒºåŸŸæ•°: {result['total_regions']}")
        print(f"ğŸ“¦ åˆå¹¶æ–‡ä»¶æ•°: {result['num_parts_merged']}")
        
    except Exception as e:
        print(f"âŒ åˆå¹¶å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 