import json
import os
import numpy as np
import matplotlib

# æ·»åŠ ä»¥ä¸‹ä»£ç æ¥å±è”½ç‰¹å®šè­¦å‘Š
import warnings
from transformers import logging as hf_logging
# å±è”½Hugging Faceçš„warning
hf_logging.set_verbosity_error()  # åªæ˜¾ç¤ºé”™è¯¯ï¼Œä¸æ˜¾ç¤ºè­¦å‘Š
# ä¹Ÿå¯ä»¥ä½¿ç”¨Pythonçš„warningsæ¨¡å—
warnings.filterwarnings("ignore", message="A decoder-only architecture is being used, but right-padding was detected")

matplotlib.use("Agg")  # è®¾ç½®åç«¯ä¸ºAggï¼ˆéäº¤äº’å¼ï¼‰
import matplotlib.pyplot as plt
import sklearn.metrics as metrics
from datetime import datetime
import gc

# --- PyTorch packages ---
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torch.utils.data as data
from torch.utils.tensorboard import SummaryWriter

import torchvision.models as models
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torchvision.models import resnet50, ResNet50_Weights

# --- Helper Packages ---
from tqdm import tqdm

# --- Project Packages ---
from utils import *
from datasets import MIMIC, mimic_collate_fn
from losses import *
from models.mrgn_model import *
from models.moe_model import *
from models.fast_rcnn_classifier import *
from models.vit import *
from models.mistral_finetuner import MistralFinetuner
from models.llama_finetuner import LlamaFinetuner
from metrics import compute_scores
from tools.optims import *
from configs import config
from tools.metrics_clinical import CheXbertMetrics

logger = setup_logger(log_dir="logs")

# --- Main Program ---
if __name__ == "__main__":
    os.environ["CUDA_VISIBLE_DEVICES"] = config.CUDA_VISIBLE_DEVICES
    torch.manual_seed(config.SEED)

    # Dataset-specific settings
    if config.DATASET_NAME == "MIMIC":
        input_size = (config.IMAGE_SIZE, config.IMAGE_SIZE)
        if config.PHASE == "FINETUNE_MISTRAL":
            tokenizer = AutoTokenizer.from_pretrained(
                "mistralai/Mistral-7B-v0.1", local_files_only=True  # å¦‚æœæ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°
            )
            tokenizer.pad_token = tokenizer.eos_token
        elif config.PHASE == "FINETUNE_LLAMA":
            tokenizer = AutoTokenizer.from_pretrained(
                "/home/chenlb/.cache/modelscope/hub/models/prithivMLmods/Llama-Doctor-3.2-3B-Instruct"
            )
            tokenizer.pad_token = tokenizer.eos_token
        else:
            tokenizer = BertTokenizer.from_pretrained(
                "bert-base-uncased", local_files_only=True
            ) 
            tokenizer.add_special_tokens({"bos_token": "[DEC]"})
        vocab_size = len(tokenizer)
        pad_id = tokenizer.pad_token_id

        MIMIC.load_shared_data(
            directory=config.DATA_DIR, 
            ann_dir=config.ANN_DIR, 
            mode=config.MODE, 
            extra_ann_dir=config.EXTRA_ANN_DIR,
            binary_mode=True
        )
        # åˆ›å»ºè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†
        train_data = MIMIC(
            directory=config.DATA_DIR,
            ann_dir=config.ANN_DIR,            
            input_size=input_size,
            random_transform=True,
            tokenizer=tokenizer,
            mode="train",
            subset_size=100 if config.DEBUG else None,
        )

        # val_data = MIMIC(
        #     directory=config.DATA_DIR,
        #     ann_dir=config.ANN_DIR,
        #     input_size=input_size,
        #     random_transform=False,
        #     tokenizer=tokenizer,
        #     mode="val",
        #     subset_size=10 if config.PHASE.startswith("TRAIN") else 100,
        # )

        test_data = MIMIC(
            directory=config.DATA_DIR,
            ann_dir=config.ANN_DIR,
            input_size=input_size,
            random_transform=False,
            tokenizer=tokenizer,
            mode="test",
            subset_size=100 if config.DEBUG else None,
        )

        comment = f"Stage{config.PHASE}"
    else:
        raise ValueError("Invalid dataset_name")

    # Model-specific settings
    if config.MODEL_NAME == "MOE":
        # åˆå§‹åŒ– TensorBoard writer
        current_time = datetime.now().strftime("%Y%m%d-%H%M%S")
        tensorboard_log_dir = os.path.join(
            config.TENSORBOARD_DIR,
            f"{config.MODEL_NAME}_{config.PHASE}_{config.CHECKPOINT_PATH_TO.split('results/')[-1][:-1].replace('/', '_')}-{current_time}",
        )
        writer = SummaryWriter(tensorboard_log_dir)
        logger.info(f"TensorBoard æ—¥å¿—ç›®å½•: {tensorboard_log_dir}")

        if config.PHASE == "TRAIN_DETECTION":
            fast_rcnn = DetectionOnlyFastRCNN()
            model = MOE(
                config=config,
                object_detector=fast_rcnn,
            )
            module_parameters = {
                "FastRCNN": count_parameters(fast_rcnn),
            }
        elif config.PHASE == "INFER_DETECTION":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(
                config.DETECTION_CHECKPOINT_PATH_FROM,
                detection_model,
                load_model="object_detector",
            )
            
            # åˆ›å»ºMOEæ¨¡å‹ï¼Œä½†åªä½¿ç”¨æ£€æµ‹å™¨éƒ¨åˆ†
            model = MOE(
                config=config,
                object_detector=detection_model,
            )
            
            # è®¡ç®—å‚æ•°é‡
            module_parameters = {
                "FastRCNN (inference only)": count_parameters(detection_model),
            }
        elif config.PHASE == "PRETRAIN_VIT":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(config.DETECTION_CHECKPOINT_PATH_FROM, detection_model)

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            cxr_bert = CXR_BERT_FeatureExtractor()

            # åˆ›å»ºMOEæ¨¡å‹
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
                cxr_bert=cxr_bert,
            )
            
            # åŠ è½½è§£å‰–åŒºåŸŸæ•°æ®åº“ï¼ˆç”¨äºåŒºåŸŸçº§åˆ«å¯¹æ¯”å­¦ä¹ ï¼‰
            if getattr(config, 'ENABLE_REGION_ITC', True):
                anatomical_db_path = getattr(config, 'ANATOMICAL_DATABASE_PATH', None)
                if anatomical_db_path:
                    MIMIC.load_anatomical_embeddings(anatomical_db_path)
                    logger.info("âœ… è§£å‰–åŒºåŸŸæ•°æ®åº“å·²åŠ è½½åˆ°MIMICæ•°æ®é›†ä¸­")
                else:
                    logger.warning("âš ï¸  æœªé…ç½®è§£å‰–åŒºåŸŸæ•°æ®åº“è·¯å¾„ï¼ŒåŒºåŸŸçº§åˆ«ITCå°†è¢«ç¦ç”¨")

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            module_parameters = {
                "Enhanced FastRCNN": count_parameters(enhanced_rcnn),
                "ViT": count_parameters(vit_model),
                "CXR BERT": count_parameters(cxr_bert),
            }
        elif config.PHASE == "INFER_BERT":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from models.bert_cross_decoder import BertCrossDecoder
            from models.moe_bert_adapter import MoEBertAdapter

            # BERTè§£ç å™¨ç”Ÿæˆæ¨¡å‹
            bert_model = MoEBertAdapter(
                config=config,
                tokenizer=tokenizer,
                hidden_dim=768,
                max_length=100
            )

            # åˆ›å»ºMOEæ¨¡å‹ï¼ˆå’ŒFINETUNE_BERTç›¸åŒçš„ç»“æ„ï¼‰
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
                findings_decoder=bert_model,
            )

            # å†»ç»“æ‰€æœ‰å‚æ•°ï¼ˆæ¨ç†é˜¶æ®µä¸éœ€è¦è®­ç»ƒï¼‰
            for param in model.object_detector.parameters():
                param.requires_grad = False
            for param in model.image_encoder.parameters():
                param.requires_grad = False
            for param in model.findings_decoder.parameters():
                param.requires_grad = False

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            module_parameters = {
                "Enhanced FastRCNN (frozen)": count_parameters(enhanced_rcnn),
                "ViT (frozen)": count_parameters(vit_model),
                "BERT Decoder (frozen)": count_parameters(bert_model),
            }
        elif config.PHASE == "FINETUNE_MISTRAL":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(
                config.DETECTION_CHECKPOINT_PATH_FROM,
                detection_model,
                load_model="object_detector",
            )

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            # åŠ è½½é¢„è®­ç»ƒçš„ViTæ¨¡å‹
            _, _ = load(config.VIT_CHECKPOINT_PATH_FROM, vit_model, load_model="vit")

            # Mistralç”Ÿæˆæ¨¡å‹
            mistral_model = MistralFinetuner(
                config=config,
                base_model=config.MISTRAL_BASE_MODEL
                if hasattr(config, "MISTRAL_BASE_MODEL")
                else "mistralai/Mistral-7B-v0.1",
                lora_r=config.LORA_R if hasattr(config, "LORA_R") else 16,
                lora_alpha=config.LORA_ALPHA if hasattr(config, "LORA_ALPHA") else 32,
                lora_dropout=config.LORA_DROPOUT
                if hasattr(config, "LORA_DROPOUT")
                else 0.05,
                load_in_4bit=config.LOAD_IN_4BIT
                if hasattr(config, "LOAD_IN_4BIT")
                else True,
            )

            # åˆ›å»ºMOEæ¨¡å‹
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
                findings_decoder=mistral_model,
            )

            # å†»ç»“å‰ä¸¤ä¸ªé˜¶æ®µçš„æ¨¡å‹å‚æ•°
            for param in model.object_detector.parameters():
                param.requires_grad = False
            # æ³¨é‡Šæ‰å†»ç»“ViTçš„ä»£ç 
            # for param in model.image_encoder.parameters():
            #     param.requires_grad = False

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            module_parameters = {
                "Enhanced FastRCNN (frozen)": count_parameters(enhanced_rcnn),
                "ViT (trainable)": count_parameters(vit_model),
                "Mistral Generator": count_parameters(mistral_model),
            }
            
        elif config.PHASE == "FINETUNE_LLAMA":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(
                config.DETECTION_CHECKPOINT_PATH_FROM,
                detection_model,
                load_model="object_detector",
            )

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            # åŠ è½½é¢„è®­ç»ƒçš„ViTæ¨¡å‹
            _, _ = load(config.VIT_CHECKPOINT_PATH_FROM, vit_model, load_model="vit")

            # Llama 3.2 3B ç”Ÿæˆæ¨¡å‹
            llama_model = LlamaFinetuner(
                config=config,
                base_model="/home/chenlb/.cache/modelscope/hub/models/prithivMLmods/Llama-Doctor-3.2-3B-Instruct",
                lora_r=config.LORA_R if hasattr(config, "LORA_R") else 16,
                lora_alpha=config.LORA_ALPHA if hasattr(config, "LORA_ALPHA") else 32,
                lora_dropout=config.LORA_DROPOUT if hasattr(config, "LORA_DROPOUT") else 0.05,
                load_in_4bit=config.LOAD_IN_4BIT if hasattr(config, "LOAD_IN_4BIT") else True,
            )

            # åˆ›å»ºMOEæ¨¡å‹
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
                findings_decoder=llama_model,
            )

            # å†»ç»“å‰ä¸¤ä¸ªé˜¶æ®µçš„æ¨¡å‹å‚æ•°
            for param in model.object_detector.parameters():
                param.requires_grad = False
            # æ³¨é‡Šæ‰å†»ç»“ViTçš„ä»£ç 
            # for param in model.image_encoder.parameters():
            #     param.requires_grad = False

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            module_parameters = {
                "Enhanced FastRCNN (frozen)": count_parameters(enhanced_rcnn),
                "ViT (trainable)": count_parameters(vit_model),
                "Llama 3.2 3B Generator": count_parameters(llama_model),
            }
        elif config.PHASE == "FINETUNE_BERT":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(
                config.DETECTION_CHECKPOINT_PATH_FROM,
                detection_model,
                load_model="object_detector",
            )

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            # åŠ è½½é¢„è®­ç»ƒçš„ViTæ¨¡å‹
            _, _ = load(config.VIT_CHECKPOINT_PATH_FROM, vit_model, load_model="vit")

            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from models.bert_cross_decoder import BertCrossDecoder
            from models.moe_bert_adapter import MoEBertAdapter

            # BERTè§£ç å™¨ç”Ÿæˆæ¨¡å‹
            bert_model = MoEBertAdapter(
                config=config,
                tokenizer=tokenizer,
                hidden_dim=768,
                max_length=100
            )

            # åˆ›å»ºMOEæ¨¡å‹
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
                findings_decoder=bert_model,
            )

            # å†»ç»“å‰ä¸¤ä¸ªé˜¶æ®µçš„æ¨¡å‹å‚æ•°
            for param in model.object_detector.parameters():
                param.requires_grad = False
            
            # å†»ç»“ViTçš„é¢„è®­ç»ƒå‚æ•°ï¼Œä½†ä¿ç•™LoRAå‚æ•°å¯è®­ç»ƒ
            for name, param in model.image_encoder.named_parameters():
                if 'lora_A' in name or 'lora_B' in name:
                    # LoRAå‚æ•°ä¿æŒå¯è®­ç»ƒ
                    param.requires_grad = True
                else:
                    # å†»ç»“å…¶ä»–æ‰€æœ‰å‚æ•°ï¼ˆé¢„è®­ç»ƒçš„encoderã€åˆ†ç±»å™¨ç­‰ï¼‰
                    param.requires_grad = False

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            # ç»Ÿè®¡ViTä¸­å¯è®­ç»ƒå’Œå†»ç»“çš„å‚æ•°
            vit_trainable_params = sum(p.numel() for name, p in model.image_encoder.named_parameters() 
                                     if p.requires_grad and ('lora_A' in name or 'lora_B' in name))
            vit_frozen_params = sum(p.numel() for name, p in model.image_encoder.named_parameters() 
                                  if not p.requires_grad)
            
            module_parameters = {
                "Enhanced FastRCNN (frozen)": count_parameters(enhanced_rcnn),
                "ViT LoRA (trainable)": vit_trainable_params,
                "ViT Base (frozen)": vit_frozen_params,
                "BERT Decoder": count_parameters(bert_model),
            }

        elif config.PHASE == "BUILD_DATABASE":
            # åˆå§‹åŒ–æ£€æµ‹å™¨
            detection_model = DetectionOnlyFastRCNN()
            _, _ = load(
                config.DETECTION_CHECKPOINT_PATH_FROM,
                detection_model,
                load_model="object_detector",
            )

            # åˆ›å»ºå¢å¼ºå‹FastRCNN
            enhanced_rcnn = EnhancedFastRCNN(
                pretrained_detector=detection_model, num_regions=29, feature_dim=768
            )

            # åˆå§‹åŒ–ViTæ¨¡å‹
            vit_model = MedicalVisionTransformer()

            # åŠ è½½é¢„è®­ç»ƒçš„ViTæ¨¡å‹
            _, _ = load(config.VIT_CHECKPOINT_PATH_FROM, vit_model, load_model="vit")

            # åˆ›å»ºMOEæ¨¡å‹ï¼ˆåªéœ€è¦æ£€æµ‹å™¨å’ŒViTï¼‰
            model = MOE(
                config=config,
                object_detector=enhanced_rcnn,
                image_encoder=vit_model,
            )

            # å†»ç»“æ‰€æœ‰å‚æ•°ï¼Œä»…ç”¨äºç‰¹å¾æå–
            for param in model.parameters():
                param.requires_grad = False

            # è®¡ç®—æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
            module_parameters = {
                "Enhanced FastRCNN (frozen)": count_parameters(enhanced_rcnn),
                "ViT (frozen)": count_parameters(vit_model),
            }

        # æ‰“å°æ¯ä¸ªæ¨¡å—çš„å‚æ•°é‡
        for module_name, param_count in module_parameters.items():
            logger.info(f"{module_name}: {param_count} parameters")
    else:
        raise ValueError("Invalid model_name")

    # Data loaders
    train_loader = data.DataLoader(
        train_data,
        batch_size=config.TRAIN_BATCH_SIZE,
        shuffle=True,
        num_workers=config.NUM_WORKERS,
        # prefetch_factor=2,
        pin_memory=False,
        # drop_last=True,
        collate_fn=mimic_collate_fn,
    )
    # val_loader = data.DataLoader(
    #     val_data,
    #     batch_size=config.VAL_BATCH_SIZE,
    #     shuffle=False,
    #     num_workers=config.NUM_WORKERS,
    #     collate_fn=mimic_collate_fn,
    # )
    test_loader = data.DataLoader(
        test_data,
        batch_size=config.VAL_BATCH_SIZE,
        shuffle=False,
        num_workers=config.NUM_WORKERS,
        collate_fn=mimic_collate_fn,
    )

    # æ‰“å°æ•°é‡
    logger.info(f"Train Data Size: {len(train_data)}")
    # logger.info(f"Val Data Size: {len(val_data)}")
    logger.info(f"Test Data Size: {len(test_data)}")

    model = model.cuda()

    # åœ¨FINETUNE_MISTRALæˆ–FINETUNE_LLAMAæˆ–FINETUNE_BERTé˜¶æ®µï¼Œåªä¼˜åŒ–ç‰¹å®šå‚æ•°
    if config.PHASE.startswith("FINETUNE_"):
        # ä¼˜åŒ–è§£ç å™¨çš„å‚æ•°å’ŒViTä¸­å¯è®­ç»ƒçš„å‚æ•°ï¼ˆä¸»è¦æ˜¯LoRAå‚æ•°ï¼‰
        trainable_params = []
        # æ·»åŠ è§£ç å™¨çš„æ‰€æœ‰å‚æ•°
        trainable_params.extend([p for p in model.findings_decoder.parameters() if p.requires_grad])
        # æ·»åŠ ViTä¸­å¯è®­ç»ƒçš„å‚æ•°ï¼ˆåœ¨FINETUNE_BERTé˜¶æ®µä¸»è¦æ˜¯LoRAå‚æ•°ï¼‰
        trainable_params.extend([p for p in model.image_encoder.parameters() if p.requires_grad])
        
        logger.info(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {sum(p.numel() for p in trainable_params)}")
        
        optimizer = optim.AdamW(
            trainable_params,
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY,
        )
    elif config.PHASE in ['BUILD_DATABASE', 'INFER_BERT']:
        optimizer = None
    else:
        optimizer = optim.AdamW(
            filter(lambda p: p.requires_grad, model.parameters()),
            lr=config.LEARNING_RATE,
            weight_decay=config.WEIGHT_DECAY,
        )

    if optimizer is not None:
        scheduler = LinearWarmupCosineLRScheduler(
            optimizer,
            config.EPOCHS,
            config.MIN_LR,
            config.LEARNING_RATE,
            decay_rate=None,
            warmup_start_lr=config.WARMUP_LR,
            warmup_steps=config.WARMUP_STEPS,
        )
    else:
        scheduler = None

    logger.info(f"Total Parameters: {sum(p.numel() for p in model.parameters())}")

    last_epoch = -1
    best_metric = -1e9

    now = datetime.now()  # current date and time
    date_time = now.strftime("%Y-%m-%d_%H:%M:%S")

    # Load checkpoint if needed (ä½†åœ¨INFER_BERTé˜¶æ®µå°†åœ¨åé¢å•ç‹¬å¤„ç†)
    if config.CHECKPOINT_PATH_FROM and config.PHASE != "INFER_BERT":
        loaded_data = load(
            config.CHECKPOINT_PATH_FROM, model, optimizer, scheduler, load_model="full"
        )
        if isinstance(loaded_data, tuple):
            last_epoch, metrics = loaded_data
            if metrics is not None and isinstance(metrics, tuple):
                best_metric, test_metric = metrics
                logger.info(
                    f"ä» {config.CHECKPOINT_PATH_FROM} åŠ è½½æ¨¡å‹æƒé‡: ä¸Šæ¬¡è®­ç»ƒè½®æ¬¡ {last_epoch}, æœ€ä½³æŒ‡æ ‡ {best_metric}, æµ‹è¯•æŒ‡æ ‡ {test_metric}"
                )
            else:
                logger.info(
                    f"ä» {config.CHECKPOINT_PATH_FROM} åŠ è½½æ¨¡å‹æƒé‡: ä¸Šæ¬¡è®­ç»ƒè½®æ¬¡ {last_epoch}, æ— æŒ‡æ ‡æ•°æ®"
                )
        else:
            last_epoch = -1
            logger.info(f"ä» {config.CHECKPOINT_PATH_FROM} åŠ è½½æ¨¡å‹æƒé‡å¤±è´¥ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
    metrics = compute_scores

    # INFER_DETECTIONé˜¶æ®µï¼šç”¨äºç”Ÿæˆæ‰€æœ‰è®­ç»ƒå’ŒéªŒè¯é›†çš„bboxå¹¶ä¿å­˜ä¸ºjsonæ–‡ä»¶
    if config.PHASE == "INFER_DETECTION":
        logger.info("å¼€å§‹INFER_DETECTIONé˜¶æ®µï¼šæ¨æ–­æ‰€æœ‰æ ·æœ¬çš„bbox...")
        
        # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        # åˆ›å»ºå­˜å‚¨æ£€æµ‹ç»“æœçš„å­—å…¸
        detection_results = {}
        
        # å®šä¹‰å¤„ç†å•ä¸ªæ•°æ®é›†çš„å‡½æ•°
        def process_dataset(data_loader, split_name):
            logger.info(f"å¤„ç†{split_name}æ•°æ®é›†...")
            
            for batch_idx, batch in enumerate(tqdm(data_loader, desc=f"Processing {split_name}")):
                images = batch["image"].cuda()
                image_paths = batch["image_path"]
                
                # æ‰§è¡Œæ¨æ–­ï¼Œè·å–æ£€æµ‹ç»“æœ
                with torch.no_grad():
                    if hasattr(model.object_detector, "predict_regions"):
                        # å¦‚æœæ˜¯DetectionOnlyFastRCNNç±»å®ä¾‹
                        detections = model.object_detector.predict_regions(images)
                    else:
                        # å¦‚æœç›®æ ‡æ£€æµ‹å™¨åœ¨MOEæ¨¡å‹å†…éƒ¨
                        outputs = model.object_detector(images)
                        detections = outputs
                
                # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†
                for i, (img_path, detection) in enumerate(zip(image_paths, detections)):
                    # æå–å›¾åƒID
                    image_id = os.path.basename(img_path).split('.')[0]
                    
                    # å°†æ£€æµ‹ç»“æœè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œæ–¹ä¾¿ä¿å­˜ä¸ºjson
                    boxes = detection["boxes"].cpu().numpy().tolist()
                    labels = detection["labels"].cpu().numpy().tolist()
                    scores = detection["scores"].cpu().numpy().tolist()
                    
                    # ä¿å­˜åˆ°å­—å…¸ä¸­
                    detection_results[image_id] = {
                        "boxes": boxes,
                        "labels": labels,
                        "scores": scores
                    }
        
        # å¤„ç†è®­ç»ƒé›†
        process_dataset(train_loader, "train")
        
        # å¤„ç†éªŒè¯é›†
        # process_dataset(val_loader, "val")
        
        # å¤„ç†æµ‹è¯•é›†
        process_dataset(test_loader, "test")
        
        # ä¿å­˜ç»“æœåˆ°jsonæ–‡ä»¶
        output_path = os.path.join(config.CHECKPOINT_PATH_TO, "detection_results.json")
        with open(output_path, 'w') as f:
            json.dump(detection_results, f)
        
        logger.info(f"æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ° {output_path}")
        logger.info("INFER_DETECTIONé˜¶æ®µå®Œæˆ")

    # Training phase
    elif config.PHASE == "TRAIN_DETECTION" or config.PHASE == "PRETRAIN_VIT":
        criterion = None
        scaler = torch.amp.GradScaler("cuda")

        for epoch in range(last_epoch + 1, config.EPOCHS):
            print(f"Epoch: {epoch}")
            train_loss = train(
                config,
                train_loader,
                model,
                optimizer,
                criterion,
                config.EPOCHS,
                epoch,
                scheduler=scheduler,
                device="cuda",
                kw_src=config.KW_SRC,
                kw_tgt=config.KW_TGT,
                scaler=scaler,
                writer=writer,
            )
            if config.PHASE == "TRAIN_DETECTION":
                test_loss, result = test_detection(
                    config=config,
                    model=model.object_detector,
                    data_loader=test_loader,
                    logger=logger,
                    epoch=epoch,
                    writer=writer,
                )
                save_path = os.path.join(
                    config.CHECKPOINT_PATH_TO,
                    f'epoch_{epoch}_{result["overall_metrics"]["mAP"]}.pth',
                )

            elif config.PHASE == "PRETRAIN_VIT":
                test_loss, result = test_vit(
                    config=config,
                    model=model,
                    data_loader=test_loader,
                    logger=logger,
                    mode="test",
                    epoch=epoch,
                    writer=writer,
                )
                save_path = os.path.join(
                    config.CHECKPOINT_PATH_TO,
                    f'epoch_{epoch}_image_acc_{result["overall_metrics"]["ce_f1"]:.4f}.pth',
                )
            else:
                pass

            save(
                save_path,
                model,
                optimizer,
                scheduler,
                epoch,
                (test_loss, result),
            )

        # å…³é—­ TensorBoard writer
        writer.close()
    elif config.PHASE == "INFER_BERT":
        # ç¡®ä¿æä¾›äº†checkpointè·¯å¾„
        if not config.CHECKPOINT_PATH_FROM:
            raise ValueError("INFER_BERTé˜¶æ®µå¿…é¡»æä¾›checkpointè·¯å¾„ç”¨äºæ¨ç†!")

        # ğŸ”§ ä¿®å¤æƒé‡åŠ è½½é—®é¢˜ï¼šä½¿ç”¨ä¸FINETUNE_BERTç›¸åŒçš„åŠ è½½æ–¹å¼
        # åˆ†åˆ«åŠ è½½ä¸åŒç»„ä»¶çš„æƒé‡ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªæ¨¡å‹
        
        # 1. åŠ è½½å›¾åƒç¼–ç å™¨æƒé‡ï¼ˆViTï¼‰
        if hasattr(config, 'IMAGE_ENCODER_CHECKPOINT_PATH_FROM') and config.IMAGE_ENCODER_CHECKPOINT_PATH_FROM:
            _, _ = load(config.IMAGE_ENCODER_CHECKPOINT_PATH_FROM, model.image_encoder, load_model="vit")
            logger.info(f"ä» {config.IMAGE_ENCODER_CHECKPOINT_PATH_FROM} åŠ è½½å›¾åƒç¼–ç å™¨æƒé‡")
        
        # 2. åŠ è½½ç›®æ ‡æ£€æµ‹å™¨æƒé‡  
        if hasattr(config, 'DETECTION_CHECKPOINT_PATH_FROM') and config.DETECTION_CHECKPOINT_PATH_FROM:
            _, _ = load(config.DETECTION_CHECKPOINT_PATH_FROM, model.object_detector, load_model="object_detector")
            logger.info(f"ä» {config.DETECTION_CHECKPOINT_PATH_FROM} åŠ è½½ç›®æ ‡æ£€æµ‹å™¨æƒé‡")
        
        # 3. ğŸš€ å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸FINETUNE_BERTç›¸åŒçš„æ–¹å¼åŠ è½½BERTè§£ç å™¨æƒé‡
        logger.info("æ­£åœ¨åŠ è½½BERTè§£ç å™¨æƒé‡...")
        _, _ = load(config.CHECKPOINT_PATH_FROM, model.findings_decoder.decoder, load_model="decoder")
        logger.info(f"ä» {config.CHECKPOINT_PATH_FROM} åŠ è½½BERTè§£ç å™¨æƒé‡åˆ° model.findings_decoder.decoder")
        
        # 4. å¦‚æœæœ‰å…¶ä»–ç»„ä»¶éœ€è¦åŠ è½½ï¼Œå¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        
        logger.info("æƒé‡åŠ è½½å®Œæˆï¼")
        
        # ğŸ”§ ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        model.eval()
        for param in model.parameters():
            param.requires_grad = False
        logger.info("æ¨¡å‹å·²è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œæ‰€æœ‰å‚æ•°å·²å†»ç»“")

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜çš„æ£€æµ‹ç»“æœ
        detection_cache_path = os.path.join(config.CHECKPOINT_PATH_TO, "detection_cache.json")
        use_cached_detections = False
        
        if os.path.exists(detection_cache_path):
            logger.info(f"å‘ç°æ£€æµ‹ç»“æœç¼“å­˜æ–‡ä»¶: {detection_cache_path}")
            try:
                with open(detection_cache_path, 'r') as f:
                    detection_cache = json.load(f)
                use_cached_detections = True
                logger.info(f"æˆåŠŸåŠ è½½ {len(detection_cache)} ä¸ªæ ·æœ¬çš„æ£€æµ‹ç¼“å­˜")
            except Exception as e:
                logger.warning(f"åŠ è½½æ£€æµ‹ç¼“å­˜å¤±è´¥: {e}ï¼Œå°†é‡æ–°è¿›è¡Œæ£€æµ‹")
                use_cached_detections = False
        else:
            logger.info("æœªæ‰¾åˆ°æ£€æµ‹ç»“æœç¼“å­˜ï¼Œå°†è¿›è¡Œé¦–æ¬¡æ£€æµ‹å¹¶ä¿å­˜ç¼“å­˜")
            use_cached_detections = False
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œå…ˆè¿›è¡Œbboxæ£€æµ‹å¹¶ä¿å­˜ï¼ˆåªç”¨ç›®æ ‡æ£€æµ‹å™¨ï¼‰
        if not use_cached_detections:
            logger.info("æ­£åœ¨ç”Ÿæˆbboxæ£€æµ‹ç¼“å­˜...")
            detection_cache = {}
            
            # åˆ›å»ºç‹¬ç«‹çš„æ£€æµ‹å™¨ç”¨äºbboxé¢„æµ‹
            cache_detector = DetectionOnlyFastRCNN()
            _, _ = load(config.DETECTION_CHECKPOINT_PATH_FROM, cache_detector, load_model="object_detector")
            cache_detector = cache_detector.cuda()
            cache_detector.eval()
            
            with torch.no_grad():
                cache_progress = tqdm(test_loader, desc="ç”Ÿæˆbboxç¼“å­˜")
                for batch_idx, batch in enumerate(cache_progress):
                    images = batch["image"].cuda()
                    image_paths = batch["image_path"]
                    
                    # åªè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè·å–bboxé¢„æµ‹
                    detections = cache_detector.predict_regions(images)
                    
                    # ä¿å­˜æ¯ä¸ªæ ·æœ¬çš„bboxé¢„æµ‹ç»“æœ
                    for i, img_path in enumerate(image_paths):
                        image_id = os.path.basename(img_path).split('.')[0]
                        
                        # æå–å•ä¸ªæ ·æœ¬çš„bboxé¢„æµ‹ï¼ˆ29ä¸ªåŒºåŸŸï¼‰
                        sample_detection = {
                            "boxes": detections[i]["boxes"].cpu().numpy().tolist(),  # é¢„æµ‹çš„bboxåæ ‡
                            "labels": detections[i]["labels"].cpu().numpy().tolist(),  # åŒºåŸŸæ ‡ç­¾
                            "scores": detections[i]["scores"].cpu().numpy().tolist()   # ç½®ä¿¡åº¦åˆ†æ•°
                        }
                        
                        detection_cache[image_id] = sample_detection
            
            # æ¸…ç†ä¸´æ—¶æ£€æµ‹å™¨
            del cache_detector
            torch.cuda.empty_cache()
            
            # ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶
            os.makedirs(os.path.dirname(detection_cache_path), exist_ok=True)
            with open(detection_cache_path, 'w') as f:
                json.dump(detection_cache, f)
            logger.info(f"bboxæ£€æµ‹ç¼“å­˜å·²ä¿å­˜åˆ°: {detection_cache_path}")

        # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½è¢«å†»ç»“ï¼ˆæ¨ç†æ¨¡å¼ï¼‰
        for param in model.parameters():
            param.requires_grad = False

        # åˆå§‹åŒ–CheXbertè¯„ä¼°å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        chexbert_metrics = None
        if hasattr(config, 'CHEXBERT_CHECKPOINT_PATH') and config.CHEXBERT_CHECKPOINT_PATH:
            try:
                from tools.metrics_clinical import CheXbertMetrics
                chexbert_metrics = CheXbertMetrics(
                    checkpoint_path=config.CHEXBERT_CHECKPOINT_PATH,
                    mbatch_size=config.VAL_BATCH_SIZE,
                    device="cuda"
                )
                logger.info("CheXbertè¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                logger.warning(f"CheXbertè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # è®¾ç½®ä½¿ç”¨ç¼“å­˜çš„æ ‡å¿—ï¼Œä¼ é€’ç»™æ¨¡å‹
        model.use_detection_cache = True
        model.detection_cache = detection_cache
        logger.info("å¯ç”¨bboxç¼“å­˜æ¨¡å¼è¿›è¡Œæ¨ç†...")

        # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†å’Œè¯„ä¼°
        logger.info("å¼€å§‹INFER_BERTé˜¶æ®µï¼šåœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæ¨ç†å’Œè¯„ä¼°...")
        
        test_loss, result = test_llm(
            config=config,
            data_loader=test_loader,
            model=model,
            logger=logger,
            metric_ftns=compute_scores,
            mode="test",
            device="cuda",
            chexbert_metrics=chexbert_metrics,
        )

        # æ‰“å°æ¨ç†ç»“æœ
        if result:
            logger.info("=== INFER_BERT æ¨ç†ç»“æœ ===")
            if "report_generation_metrics" in result:
                metrics = result["report_generation_metrics"]
                logger.info(f"BLEU-1: {metrics.get('BLEU_1', 'N/A'):.4f}")
                logger.info(f"BLEU-4: {metrics.get('BLEU_4', 'N/A'):.4f}")
                logger.info(f"ROUGE-L: {metrics.get('ROUGE_L', 'N/A'):.4f}")
                
            if "chexbert_metrics" in result:
                chexbert = result["chexbert_metrics"]
                logger.info(f"CheXbert CE F1: {chexbert.get('ce_f1', 'N/A'):.4f}")
                logger.info(f"CheXbert CE Precision: {chexbert.get('ce_precision', 'N/A'):.4f}")
                logger.info(f"CheXbert CE Recall: {chexbert.get('ce_recall', 'N/A'):.4f}")

        # ä¿å­˜ç”Ÿæˆç»“æœ
        logger.info("ä¿å­˜æ¨ç†ç”Ÿæˆç»“æœ...")
        save_generations(
            config,
            test_loader,
            model,
            logger,
            save_dir=os.path.join(config.CHECKPOINT_PATH_TO, "infer_bert_generations"),
            mode="test",
            device="cuda",
            kw_src=config.KW_SRC,
            kw_tgt=config.KW_TGT,
        )

    # ç»Ÿä¸€å¤„ç†æ‰€æœ‰å¾®è°ƒé˜¶æ®µ(MISTRAL/LLAMA/BERT)
    elif config.PHASE.startswith("FINETUNE_"):
        # å¾®è°ƒé˜¶æ®µ
        if config.DECODER_CHECKPOINT_PATH_FROM:
            if config.PHASE == "FINETUNE_LLAMA":
                # LLAMAä½¿ç”¨ç‰¹æ®Šçš„åŠ è½½å™¨
                _, _ = load(config.DECODER_CHECKPOINT_PATH_FROM, model.findings_decoder, optimizer, scheduler, load_model="decoder")
            elif config.PHASE == "FINETUNE_BERT":
                # BERTä½¿ç”¨æ ‡å‡†åŠ è½½å™¨ï¼Œä½†å¯ä»¥æŒ‡å®šåªåŠ è½½decoderéƒ¨åˆ†
                _, _ = load(config.DECODER_CHECKPOINT_PATH_FROM, model.findings_decoder.decoder, optimizer, scheduler, load_model="decoder")
            else:
                # MISTRALä½¿ç”¨æ ‡å‡†åŠ è½½å™¨
                _, _ = load(config.DECODER_CHECKPOINT_PATH_FROM, model, optimizer, scheduler)
            logger.info(f"ä» {config.DECODER_CHECKPOINT_PATH_FROM} åŠ è½½æ¨¡å‹æƒé‡")

        # åˆå§‹åŒ–CheXbertè¯„ä¼°å™¨
        logger.info("åˆå§‹åŒ–CheXbertè¯„ä¼°å™¨...")
        chexbert_path = config.CHEXBERT_CHECKPOINT_PATH
        try:
            chexbert_metrics = CheXbertMetrics(
                checkpoint_path=chexbert_path,
                mbatch_size=config.VAL_BATCH_SIZE,
                device="cuda"
            )
            logger.info(f"CheXbertè¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸï¼Œä½¿ç”¨æ£€æŸ¥ç‚¹: {chexbert_path}")
        except Exception as e:
            logger.error(f"CheXbertè¯„ä¼°å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            chexbert_metrics = None
        
        
        criterion = None
        scaler = torch.amp.GradScaler() if config.USE_MIXED_PRECISION else None

        for epoch in range(last_epoch + 1, config.EPOCHS):
            logger.info(f"Epoch: {epoch}")

            # è®­ç»ƒ
            train_loss = train(
                config,
                train_loader,
                model,
                optimizer,
                criterion,
                config.EPOCHS,
                epoch,
                scheduler=scheduler,
                device="cuda",
                kw_src=config.KW_SRC,
                kw_tgt=config.KW_TGT,
                scaler=scaler,
                writer=writer,
            )

            # æ¯5è½®è¿›è¡Œä¸€æ¬¡æµ‹è¯•
            # if (epoch + 1) % 5 == 0 or epoch == config.EPOCHS - 1:
            if epoch == config.EPOCHS - 1:
                # æµ‹è¯•
                test_loss, result = test_llm(
                    config=config,
                    data_loader=test_loader,
                    model=model,
                    logger=logger,
                    metric_ftns=compute_scores,
                    mode="test",
                    device="cuda",
                    epoch=epoch,
                    writer=writer,
                    chexbert_metrics=chexbert_metrics,
                )

                # ä¿å­˜æ£€æŸ¥ç‚¹ - ä½¿ç”¨CheXbertæŒ‡æ ‡å¦‚æœå¯ç”¨
                if chexbert_metrics is not None and "chexbert_metrics" in result and "ce_f1" in result["chexbert_metrics"]:
                    save_path = os.path.join(
                        config.CHECKPOINT_PATH_TO,
                        f'epoch_{epoch}_bleu_{result["report_generation_metrics"]["BLEU_1"]:.4f}_ce_f1_{result["chexbert_metrics"]["ce_f1"]:.4f}.pth',
                    )
                else:
                    save_path = os.path.join(
                        config.CHECKPOINT_PATH_TO,
                        f'epoch_{epoch}_bleu_{result["report_generation_metrics"]["BLEU_1"]:.4f}.pth',
                    )

                save(
                    save_path,
                    model,
                    optimizer,
                    scheduler,
                    epoch,
                    (test_loss, result),
                )
            else:
                # éæµ‹è¯•è½®æ¬¡ä¹Ÿä¿å­˜æ£€æŸ¥ç‚¹ï¼Œä½†ä¸åŒ…å«æµ‹è¯•æŒ‡æ ‡
                save_path = os.path.join(
                    config.CHECKPOINT_PATH_TO,
                    f'epoch_{epoch}.pth',
                )
                save(
                    save_path,
                    model,
                    optimizer,
                    scheduler,
                    epoch,
                    None,  # ä¸åŒ…å«æµ‹è¯•ç»“æœ
                )

            # æ¯ä¸ªepochåæ¸…ç†å†…å­˜
            torch.cuda.empty_cache()
            gc.collect()

        # å…³é—­TensorBoard writer
        writer.close()

        # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°
        logger.info("åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œæœ€ç»ˆè¯„ä¼°...")
        final_test_loss, final_test_result = test_llm(
            config=config,
            data_loader=test_loader,
            model=model,
            logger=logger,
            metric_ftns=compute_scores,
            mode="test",
            device="cuda",
            chexbert_metrics=chexbert_metrics,
        )

        # # æ‰“å°æœ€ç»ˆç»“æœ
        # logger.info(
        #     f"éªŒè¯é›† - BLEU-4: {final_val_result['report_generation_metrics']['bleu4']:.4f}, ROUGE-L: {final_val_result['report_generation_metrics']['rougeL']:.4f}"
        # )
        # logger.info(
        #     f"æµ‹è¯•é›† - BLEU-4: {final_test_result['report_generation_metrics']['bleu4']:.4f}, ROUGE-L: {final_test_result['report_generation_metrics']['rougeL']:.4f}"
        # )

    elif config.PHASE == "BUILD_DATABASE":
        # BUILD_DATABASEé˜¶æ®µï¼šæ„å»ºè§£å‰–åŒºåŸŸç‰¹å¾æ•°æ®åº“
        logger.info("å¼€å§‹BUILD_DATABASEé˜¶æ®µï¼šæ„å»ºè§£å‰–åŒºåŸŸç‰¹å¾æ•°æ®åº“...")
        
        from utils import build_anatomical_database
        
        # æ„å»ºæ•°æ®åº“
        build_anatomical_database(
            config=config,
            model=model,
            data_loader=train_loader,
            logger=logger,
            device="cuda"
        )
        
        logger.info("è§£å‰–åŒºåŸŸç‰¹å¾æ•°æ®åº“æ„å»ºå®Œæˆï¼")

    elif config.MODE == "TEST":
        # ç¡®ä¿æä¾›äº†checkpointè·¯å¾„
        if not config.CHECKPOINT_PATH_FROM:
            raise ValueError("å¿…é¡»æä¾›checkpointè·¯å¾„ç”¨äºæµ‹è¯•!")

        # åŠ è½½æ¨¡å‹æƒé‡
        _, _ = load(config.CHECKPOINT_PATH_FROM, model, optimizer, scheduler)
        logger.info(f"ä» {config.CHECKPOINT_PATH_FROM} åŠ è½½æ¨¡å‹æƒé‡")

        # ä¿å­˜ç”Ÿæˆç»“æœ
        save_generations(
            config,
            test_loader,
            model,
            logger,
            save_dir=os.path.join(config.CHECKPOINT_PATH_TO, "generations"),
            mode="test",
            device="cuda",
            kw_src=config.KW_SRC,
            kw_tgt=config.KW_TGT,
        )

    else:
        raise ValueError("Invalid phase")
